epoch,train_loss,val_pr_auc,val_roc_auc,val_acc,val_precision,val_recall,val_f1
1,0.00684034690645826,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
2,1.3490431044804233e-06,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
3,5.554913807517635e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
4,3.644304970781531e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
5,2.2196920606630958e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
6,1.6722180713400702e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
7,1.1617146240361702e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
8,1.0088127467087088e-07,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
9,8.396888201302907e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
10,5.635759691424452e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
11,4.6046303949048134e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
12,4.0046311844149683e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
13,3.023829164877368e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
14,2.592700886713648e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
15,1.777732166831973e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
16,2.2928384139999202e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
17,1.4318871706808017e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
18,1.6171836220710463e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
19,1.1045515401696754e-08,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
20,8.207637723590599e-09,0.9999692855826525,0.0,1.0,1.0,1.0,1.0
